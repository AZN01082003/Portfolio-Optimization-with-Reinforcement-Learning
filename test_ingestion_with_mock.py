#!/usr/bin/env python3
"""
Test d'ingestion avec donn√©es fictives pour √©viter les probl√®mes de rate limiting.
√Ä placer √† la racine du projet : test_ingestion_with_mock.py
"""
import os
import sys
import json
import tempfile
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Ajouter le r√©pertoire du projet au PYTHONPATH
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

def create_test_config():
    """Cr√©e un fichier de configuration de test."""
    config = {
        "data": {
            "tickers": ["AAPL", "MSFT"],
            "lookback_years": 0.1,
            "train_ratio": 0.7,
            "output_dir": "data/processed"
        },
        "environment": {
            "portfolio_value": 10000,
            "window_size": 30,
            "trans_cost": 0.0005,
            "return_rate": 0.0001,
            "reward_scaling": 100.0,
            "max_reward_clip": 5.0,
            "min_reward_clip": -5.0
        }
    }
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        json.dump(config, f, indent=2)
        return f.name

def create_mock_stock_data(tickers, start_date, end_date):
    """Cr√©e des donn√©es d'actions fictives pour le test."""
    print("üìä Cr√©ation de donn√©es fictives pour √©viter le rate limiting...")
    
    # Cr√©er une plage de dates
    dates = pd.date_range(start=start_date, end=end_date, freq='D')
    dates = dates[dates.dayofweek < 5]  # Seulement les jours ouvrables
    
    if len(dates) == 0:
        # Si pas de jours ouvrables, cr√©er au moins quelques points
        dates = pd.date_range(start=start_date, periods=5, freq='D')
    
    # Cr√©er un MultiIndex pour les colonnes (comme yfinance)
    columns = pd.MultiIndex.from_product([
        ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'],
        tickers
    ])
    
    # Initialiser le DataFrame
    data = pd.DataFrame(index=dates, columns=columns)
    
    # Remplir avec des donn√©es r√©alistes
    for ticker in tickers:
        # Prix de base (diff√©rent pour chaque ticker)
        base_price = 100 if ticker == 'AAPL' else 250
        
        # G√©n√©rer des prix avec une marche al√©atoire
        returns = np.random.normal(0.001, 0.02, len(dates))  # 0.1% de rendement moyen, 2% de volatilit√©
        prices = base_price * np.exp(np.cumsum(returns))
        
        # OHLC r√©aliste
        for i, price in enumerate(prices):
            daily_volatility = 0.01  # 1% de volatilit√© intraday
            high = price * (1 + np.random.uniform(0, daily_volatility))
            low = price * (1 - np.random.uniform(0, daily_volatility))
            open_price = price * (1 + np.random.uniform(-daily_volatility/2, daily_volatility/2))
            close = price
            
            data.loc[dates[i], ('Open', ticker)] = open_price
            data.loc[dates[i], ('High', ticker)] = high
            data.loc[dates[i], ('Low', ticker)] = low
            data.loc[dates[i], ('Close', ticker)] = close
            data.loc[dates[i], ('Adj Close', ticker)] = close
            data.loc[dates[i], ('Volume', ticker)] = np.random.randint(1000000, 10000000)
    
    # Convertir en float
    data = data.astype(float)
    
    print(f"‚úÖ Donn√©es fictives cr√©√©es: {data.shape}")
    return data

def test_complete_pipeline():
    """Test complet du pipeline d'ingestion avec donn√©es fictives."""
    print("üß™ Test complet du pipeline d'ingestion avec donn√©es fictives...")
    
    try:
        # Importer les modules n√©cessaires
        from src.data.ingestion import load_config, validate_tickers, save_data_with_metadata
        
        # Configuration de test
        config_path = create_test_config()
        config = load_config(config_path)
        
        # Param√®tres du test
        tickers = ["AAPL", "MSFT"]
        end_date = datetime.now()
        start_date = end_date - timedelta(days=30)
        
        print(f"üìÖ P√©riode de test: {start_date.date()} - {end_date.date()}")
        
        # Test 1: Validation des tickers
        print("\n1Ô∏è‚É£ Test de validation des tickers...")
        validated_tickers = validate_tickers(tickers)
        assert validated_tickers == ["AAPL", "MSFT"]
        print("‚úÖ Validation r√©ussie")
        
        # Test 2: Cr√©ation de donn√©es fictives
        print("\n2Ô∏è‚É£ Cr√©ation de donn√©es fictives...")
        mock_data = create_mock_stock_data(tickers, start_date, end_date)
        assert not mock_data.empty
        assert mock_data.shape[1] == 6 * len(tickers)  # 6 colonnes par ticker
        print("‚úÖ Donn√©es fictives cr√©√©es")
        
        # Test 3: Sauvegarde des donn√©es
        print("\n3Ô∏è‚É£ Test de sauvegarde...")
        
        # Cr√©er les r√©pertoires
        os.makedirs('data/raw', exist_ok=True)
        
        # M√©tadonn√©es
        metadata = {
            'tickers': tickers,
            'start_date': start_date.isoformat(),
            'end_date': end_date.isoformat(),
            'download_timestamp': datetime.now().isoformat(),
            'data_shape': list(mock_data.shape),
            'columns': [str(col) for col in mock_data.columns],
            'missing_data_count': int(mock_data.isnull().sum().sum()),
            'config_used': config_path,
            'data_source': 'mock_for_testing'
        }
        
        # Sauvegarder
        output_path = f"data/raw/stock_data_test_{end_date.strftime('%Y%m%d')}.csv"
        save_data_with_metadata(mock_data, output_path, metadata)
        
        # V√©rifier les fichiers
        assert os.path.exists(output_path)
        metadata_path = output_path.replace('.csv', '_metadata.json')
        assert os.path.exists(metadata_path)
        print("‚úÖ Sauvegarde r√©ussie")
        
        # Test 4: V√©rification de la qualit√© des donn√©es
        print("\n4Ô∏è‚É£ V√©rification de la qualit√© des donn√©es...")
        
        # Recharger les donn√©es
        reloaded_data = pd.read_csv(output_path, index_col=0, header=[0, 1])
        
        # V√©rifications
        assert reloaded_data.shape == mock_data.shape
        assert not reloaded_data.empty
        
        # V√©rifier les m√©tadonn√©es
        with open(metadata_path, 'r') as f:
            loaded_metadata = json.load(f)
        
        assert loaded_metadata['tickers'] == tickers
        assert loaded_metadata['data_source'] == 'mock_for_testing'
        assert loaded_metadata['missing_data_count'] == 0
        
        print("‚úÖ Qualit√© des donn√©es v√©rifi√©e")
        
        # Test 5: Statistiques des donn√©es
        print("\n5Ô∏è‚É£ Analyse des donn√©es...")
        
        # Calculer quelques statistiques
        for ticker in tickers:
            close_prices = mock_data[('Close', ticker)]
            daily_returns = close_prices.pct_change().dropna()
            
            print(f"   üìà {ticker}:")
            print(f"      Prix moyen: ${close_prices.mean():.2f}")
            print(f"      Rendement moyen: {daily_returns.mean()*100:.3f}%")
            print(f"      Volatilit√©: {daily_returns.std()*100:.3f}%")
        
        print("‚úÖ Analyse termin√©e")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur durant le test: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # Nettoyer
        try:
            os.unlink(config_path)
        except:
            pass

def test_real_ingestion_when_possible():
    """Test optionnel avec vraies donn√©es si possible."""
    print("\nüåê Test optionnel avec donn√©es r√©elles (si possible)...")
    
    try:
        from src.data.ingestion import main
        
        # Configuration simple
        config_path = create_test_config()
        
        # Essayer avec une p√©riode tr√®s courte et un seul ticker
        end_date = datetime.now()
        start_date = end_date - timedelta(days=2)  # Seulement 2 jours
        
        print("‚è≥ Tentative de t√©l√©chargement (2 jours, 1 ticker)...")
        
        data, tickers, config = main(
            config_path=config_path,
            tickers=["AAPL"],  # Un seul ticker
            start_date=start_date,
            end_date=end_date
        )
        
        print(f"‚úÖ T√©l√©chargement r√©el r√©ussi! Forme: {data.shape}")
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è  T√©l√©chargement r√©el √©chou√© (normal): {e}")
        print("   üí° Utilisez les donn√©es fictives pour le d√©veloppement")
        return False
    finally:
        try:
            os.unlink(config_path)
        except:
            pass

if __name__ == "__main__":
    print("üöÄ Test d'ingestion avec donn√©es fictives")
    print("=" * 60)
    
    # Cr√©er les r√©pertoires n√©cessaires
    os.makedirs("data/raw", exist_ok=True)
    os.makedirs("data/processed", exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    
    # Test principal avec donn√©es fictives
    success_mock = test_complete_pipeline()
    
    # Test optionnel avec vraies donn√©es
    success_real = test_real_ingestion_when_possible()
    
    print("\n" + "=" * 60)
    if success_mock:
        print("üéâ Tests avec donn√©es fictives r√©ussis!")
        print("\nüìã R√©sum√©:")
        print("   ‚úÖ Validation des tickers")
        print("   ‚úÖ Cr√©ation de donn√©es fictives")
        print("   ‚úÖ Sauvegarde et chargement")
        print("   ‚úÖ V√©rification de la qualit√©")
        print("   ‚úÖ Analyse statistique")
        
        if success_real:
            print("   ‚úÖ Test avec donn√©es r√©elles")
        else:
            print("   ‚ö†Ô∏è  Donn√©es r√©elles indisponibles (rate limiting)")
        
        print("\nüéØ √âTAPE 1 VALID√âE!")
        print("üìã Prochaines √©tapes:")
        print("   2. üîÑ Correction de l'environnement RL")
        print("   3. üìä Correction du preprocessing")
        print("   4. ü§ñ Validation du pipeline d'entra√Ænement")
        
    else:
        print("üí• Tests √©chou√©s.")
        sys.exit(1)
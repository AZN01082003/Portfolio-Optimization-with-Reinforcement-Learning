#!/usr/bin/env python3
"""
Test complet de l'API Portfolio RL
VÃ©rifie tous les endpoints et fonctionnalitÃ©s
"""
import requests
import time
import json
import numpy as np
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APITester:
    """Testeur pour l'API Portfolio RL."""
    
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.session = requests.Session()
        self.session.timeout = 30
    
    def test_health(self):
        """Test de l'endpoint de santÃ©."""
        logger.info("ğŸ” Test de santÃ©...")
        try:
            response = self.session.get(f"{self.base_url}/health")
            assert response.status_code == 200
            data = response.json()
            assert data['status'] == 'healthy'
            logger.info(f"âœ… SantÃ© OK: {data}")
            return True
        except Exception as e:
            logger.error(f"âŒ Test santÃ© Ã©chouÃ©: {e}")
            return False
    
    def test_root(self):
        """Test de l'endpoint racine."""
        logger.info("ğŸ” Test endpoint racine...")
        try:
            response = self.session.get(f"{self.base_url}/")
            assert response.status_code == 200
            data = response.json()
            assert 'message' in data
            logger.info(f"âœ… Racine OK: {data}")
            return True
        except Exception as e:
            logger.error(f"âŒ Test racine Ã©chouÃ©: {e}")
            return False
    
    def test_models_list(self):
        """Test de la liste des modÃ¨les."""
        logger.info("ğŸ” Test liste des modÃ¨les...")
        try:
            response = self.session.get(f"{self.base_url}/models")
            assert response.status_code == 200
            data = response.json()
            logger.info(f"âœ… ModÃ¨les OK: {data}")
            return True
        except Exception as e:
            logger.error(f"âŒ Test modÃ¨les Ã©chouÃ©: {e}")
            return False
    
    def test_prediction(self):
        """Test de prÃ©diction d'allocation."""
        logger.info("ğŸ” Test prÃ©diction...")
        try:
            # DonnÃ©es de test
            test_data = {
                "portfolio_id": "test_portfolio_001",
                "market_data": np.random.rand(5, 5, 30).tolist(),  # 5 features, 5 stocks, 30 periods
                "current_weights": [0.2, 0.2, 0.2, 0.2, 0.2],
                "portfolio_value": 100000.0,
                "risk_tolerance": 0.5
            }
            
            response = self.session.post(
                f"{self.base_url}/predict",
                json=test_data,
                headers={"Content-Type": "application/json"}
            )
            
            assert response.status_code == 200
            data = response.json()
            
            # VÃ©rifications
            assert 'recommended_weights' in data
            assert 'confidence' in data
            assert 'model_version' in data
            assert len(data['recommended_weights']) == 5
            assert 0 <= data['confidence'] <= 1
            
            # VÃ©rifier que les poids somment Ã  1
            weights_sum = sum(data['recommended_weights'])
            assert abs(weights_sum - 1.0) < 0.01, f"Somme des poids: {weights_sum}"
            
            logger.info(f"âœ… PrÃ©diction OK: {data}")
            return True, data
            
        except Exception as e:
            logger.error(f"âŒ Test prÃ©diction Ã©chouÃ©: {e}")
            return False, None
    
    def test_prediction_performance(self, n_requests=10):
        """Test de performance des prÃ©dictions."""
        logger.info(f"ğŸ” Test performance ({n_requests} requÃªtes)...")
        try:
            durations = []
            
            for i in range(n_requests):
                start_time = time.time()
                success, _ = self.test_prediction()
                duration = time.time() - start_time
                durations.append(duration)
                
                if not success:
                    logger.warning(f"âš ï¸ RequÃªte {i+1} Ã©chouÃ©e")
                    continue
                
                if i % 5 == 0:
                    logger.info(f"ğŸ“Š RequÃªte {i+1}/{n_requests} - {duration:.3f}s")
            
            if durations:
                avg_duration = sum(durations) / len(durations)
                max_duration = max(durations)
                min_duration = min(durations)
                
                logger.info(f"âœ… Performance OK:")
                logger.info(f"   Moyenne: {avg_duration:.3f}s")
                logger.info(f"   Min: {min_duration:.3f}s")
                logger.info(f"   Max: {max_duration:.3f}s")
                logger.info(f"   SuccÃ¨s: {len(durations)}/{n_requests}")
                
                return True
            else:
                logger.error("âŒ Aucune requÃªte rÃ©ussie")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Test performance Ã©chouÃ©: {e}")
            return False
    
    def test_metrics(self):
        """Test des mÃ©triques."""
        logger.info("ğŸ” Test mÃ©triques...")
        try:
            # Test endpoint mÃ©triques
            response = self.session.get(f"{self.base_url}/metrics")
            if response.status_code == 200:
                metrics_data = response.text
                logger.info(f"âœ… MÃ©triques disponibles: {len(metrics_data)} caractÃ¨res")
                
                # VÃ©rifier quelques mÃ©triques attendues
                expected_metrics = [
                    'portfolio_api_requests_total',
                    'portfolio_model_predictions_total'
                ]
                
                for metric in expected_metrics:
                    if metric in metrics_data:
                        logger.info(f"   âœ… MÃ©trique trouvÃ©e: {metric}")
                    else:
                        logger.warning(f"   âš ï¸ MÃ©trique manquante: {metric}")
                
                return True
            elif response.status_code == 404:
                logger.warning("âš ï¸ Endpoint mÃ©triques non disponible")
                return True  # Pas critique
            else:
                logger.error(f"âŒ Erreur mÃ©triques: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Test mÃ©triques Ã©chouÃ©: {e}")
            return False
    
    def test_monitoring_status(self):
        """Test du statut de monitoring."""
        logger.info("ğŸ” Test statut monitoring...")
        try:
            # VÃ©rifier si l'endpoint existe
            endpoints_to_check = ["/monitoring/status", "/health"]
            
            for endpoint in endpoints_to_check:
                try:
                    response = self.session.get(f"{self.base_url}{endpoint}")
                    if response.status_code == 200:
                        data = response.json()
                        logger.info(f"âœ… {endpoint} OK: {data}")
                except Exception as e:
                    logger.warning(f"âš ï¸ {endpoint} non disponible: {e}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Test monitoring Ã©chouÃ©: {e}")
            return False
    
    def test_error_handling(self):
        """Test de la gestion d'erreurs."""
        logger.info("ğŸ” Test gestion d'erreurs...")
        try:
            # Test avec donnÃ©es invalides
            invalid_data = {
                "portfolio_id": "test",
                "market_data": "invalid",  # Doit Ãªtre une liste
                "current_weights": [0.5, 0.5],  # Mauvaise taille
                "portfolio_value": -1000  # Valeur nÃ©gative
            }
            
            response = self.session.post(
                f"{self.base_url}/predict",
                json=invalid_data
            )
            
            # Doit retourner une erreur 422 (validation) ou 500 (serveur)
            assert response.status_code in [422, 500], f"Code inattendu: {response.status_code}"
            logger.info(f"âœ… Gestion d'erreur OK: {response.status_code}")
            
            # Test endpoint inexistant
            response = self.session.get(f"{self.base_url}/nonexistent")
            assert response.status_code == 404
            logger.info("âœ… Endpoint inexistant gÃ©rÃ© correctement")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Test gestion d'erreurs Ã©chouÃ©: {e}")
            return False
    
    def run_all_tests(self):
        """Lance tous les tests."""
        logger.info("ğŸš€ DÃ©marrage des tests complets de l'API")
        logger.info("="*50)
        
        tests = [
            ("SantÃ©", self.test_health),
            ("Endpoint racine", self.test_root),
            ("Liste modÃ¨les", self.test_models_list),
            ("PrÃ©diction", lambda: self.test_prediction()[0]),
            ("Performance", lambda: self.test_prediction_performance(5)),
            ("MÃ©triques", self.test_metrics),
            ("Monitoring", self.test_monitoring_status),
            ("Gestion d'erreurs", self.test_error_handling)
        ]
        
        results = {}
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            logger.info(f"\nğŸ“‹ Test: {test_name}")
            try:
                result = test_func()
                results[test_name] = result
                if result:
                    passed += 1
                    logger.info(f"âœ… {test_name}: PASSED")
                else:
                    logger.error(f"âŒ {test_name}: FAILED")
            except Exception as e:
                logger.error(f"âŒ {test_name}: ERROR - {e}")
                results[test_name] = False
        
        # RÃ©sumÃ©
        logger.info("\n" + "="*50)
        logger.info(f"ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
        logger.info(f"âœ… Tests rÃ©ussis: {passed}/{total}")
        logger.info(f"âŒ Tests Ã©chouÃ©s: {total - passed}/{total}")
        logger.info(f"ğŸ“ˆ Taux de rÃ©ussite: {passed/total*100:.1f}%")
        
        if passed == total:
            logger.info("ğŸ‰ Tous les tests sont passÃ©s!")
        else:
            logger.warning("âš ï¸ Certains tests ont Ã©chouÃ©")
        
        return results, passed == total

def main():
    """Fonction principale."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Test de l'API Portfolio RL")
    parser.add_argument("--url", default="http://localhost:8000", help="URL de l'API")
    parser.add_argument("--quick", action="store_true", help="Tests rapides seulement")
    parser.add_argument("--performance", type=int, default=10, help="Nombre de requÃªtes pour le test de performance")
    
    args = parser.parse_args()
    
    tester = APITester(args.url)
    
    logger.info(f"ğŸ¯ Test de l'API: {args.url}")
    
    # VÃ©rifier que l'API est accessible
    try:
        response = requests.get(f"{args.url}/health", timeout=5)
        if response.status_code != 200:
            logger.error(f"âŒ API non accessible: {response.status_code}")
            return 1
    except Exception as e:
        logger.error(f"âŒ Impossible de joindre l'API: {e}")
        logger.info("ğŸ’¡ Assurez-vous que l'API est dÃ©marrÃ©e avec: python start_api.py")
        return 1
    
    if args.quick:
        # Tests rapides
        success = all([
            tester.test_health(),
            tester.test_root(),
            tester.test_prediction()[0]
        ])
        return 0 if success else 1
    else:
        # Tests complets
        results, all_passed = tester.run_all_tests()
        return 0 if all_passed else 1

if __name__ == "__main__":
    exit(main())